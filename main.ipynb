{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import openai\n",
    "\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from consts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kns_csv_files/kns_committee.csv')\n",
    "df = df[df['KnessetNum'] >= 25]\n",
    "df = df[df['CategoryID'].isin([MONEY_COM_CATEGORY_ID, DEFENSE_COM_CATEGORY_ID, LAW_ORDER_COM_CATEGORY_ID, MESADERET_COM_CATEGORY_ID, KNESSET_COM_CATEGORY_ID])]\n",
    "commitee_ids = df['CommitteeID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_protocol_text(text_path):\n",
    "    # Define the URL to fetch\n",
    "    base_url = 'https://production.oknesset.org/pipelines/data/committees/meeting_protocols_text/'\n",
    "    # Send GET request to the URL\n",
    "    response = requests.get(base_url + text_path)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        # Retrieve the content of the file\n",
    "        return response.text\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to retrieve content. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rate_aggressiveness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1836\\2522381786.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom_session_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_parsed_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_meeting_protocol_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0magg_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrate_aggressiveness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1836\\2522381786.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom_session_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_parsed_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_meeting_protocol_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0magg_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrate_aggressiveness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rate_aggressiveness' is not defined"
     ]
    }
   ],
   "source": [
    "com_session_df = pd.read_csv('kns_csv_files/kns_committeesession.csv')\n",
    "com_session_df = com_session_df[com_session_df['CommitteeID'].isin(commitee_ids)]\n",
    "\n",
    "com_session_df.dropna(subset=['text_parsed_filename'], inplace=True)\n",
    "text_paths = com_session_df['text_parsed_filename'].to_list()\n",
    "texts = [get_meeting_protocol_text(path) for path in text_paths]\n",
    "agg_scores = [rate_aggressiveness(text) for text in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knesset_members_df = pd.read_csv('kns_csv_files/kns_person.csv')\n",
    "first_names, last_names = knesset_members_df['FirstName'].to_list(), knesset_members_df['LastName'].to_list()\n",
    "knesset_members = [' '.join([first_name, last_name]) for first_name, last_name in zip(first_names, last_names)]\n",
    "\n",
    "warnings = {mem: [0, 0, 0] for mem in knesset_members}\n",
    "\n",
    "# handle members with a middle name or a nickname\n",
    "new_first_names, new_last_names = [], []\n",
    "\n",
    "for fn, ln in zip(first_names, last_names):\n",
    "    names = re.findall('\\w+', fn)\n",
    "    \n",
    "    for name in names:\n",
    "        warnings[name + ' ' + ln] = warnings[fn + ' ' + ln]\n",
    "        new_first_names.append(name)\n",
    "        new_last_names.append(ln)\n",
    "\n",
    "# update first and last names\n",
    "first_names = new_first_names\n",
    "last_names = new_last_names\n",
    "\n",
    "knesset_members = [' '.join([first_name, last_name]) for first_name, last_name in zip(first_names, last_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_warnings(text, warnings, knesset_members) -> None:\n",
    "    \"\"\"\n",
    "    Return warnings from the meeting protocol text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Meeting protocol text.\n",
    "\n",
    "    warnings: Dict[str, List[int]]\n",
    "        Number of warnings for each Knesset member.\n",
    "\n",
    "    knesset_members: List[str]\n",
    "        List of Knesset members.\n",
    "    \"\"\"\n",
    "\n",
    "    # find all warnings\n",
    "    matches = re.findall(WARNING_REGEX, text, flags=re.MULTILINE)\n",
    "    print(len(matches))\n",
    "    for i, match in enumerate(matches):\n",
    "        print(f'match #{i}:')\n",
    "        print(match)\n",
    "        sentences = match.split('\\n')\n",
    "        first_sentence, last_sentence = sentences[0], sentences[-1]\n",
    "        for kns_member in knesset_members:\n",
    "            if kns_member in first_sentence:\n",
    "                word2idx = {'ראש': 0, 'שני': 1, 'שליש': 2}\n",
    "                for word, idx in word2idx.items():\n",
    "                    if word in last_sentence:\n",
    "                        warnings[kns_member][idx] += 1\n",
    "                        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_protocol_sentences(text: str) -> str:\n",
    "    ind = re.search(\"<< יור >>\", text)\n",
    "    txt2 = text[ind.span()[0]:]\n",
    "    txt2 = re.sub(\"<<.*\",\"\", txt2)\n",
    "    txt2 = re.sub(\">>.*\",\"\", txt2)\n",
    "    txt2 = re.sub(\"-\", \" \", txt2)\n",
    "    txt2 = re.sub(\"\\n\\s+\",\"\\n\", txt2)\n",
    "    txt2 = re.sub(\" +\",\" \", txt2)\n",
    "    return txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('protocols/2159679.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "filtered_text = filter_protocol_sentences(text)\n",
    "with open('filtered_protocols/2159679.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_aggressiveness(text):\n",
    "    filtered_text = filter_protocol_sentences(text)\n",
    "    lines = filtered_text.split('\\n')\n",
    "\n",
    "    # Filter non-conversation related lines\n",
    "    lines = [line for line in lines if line.strip() != '' and '>' not in line and '<' not in line]\n",
    "    print(lines)\n",
    "\n",
    "    # Prompt Chat-GPT to rate the aggressiveness of the text\n",
    "    scores = []\n",
    "    query = 'דרג את מידת האגרסיביות של השיחה (תשובה מספרית בלבד! מ-1 עד 5 כש-5 זה אגרסיבי מאוד)\\n'\n",
    "\n",
    "    prompt = query\n",
    "    n_tokens = len(prompt.split(' '))\n",
    "\n",
    "    for line in lines:\n",
    "        print('prompt:', prompt)\n",
    "        print('n_tokens:', n_tokens)\n",
    "        print('curr line:', line)\n",
    "\n",
    "        num_new_tokens = len(line.split(' '))\n",
    "        print('num new tokens:', num_new_tokens)\n",
    "        if n_tokens + num_new_tokens < CHATGPT_MAX_TOKENS:\n",
    "            # Maximum amount of tokens not yet exceeded, can add another sentence\n",
    "            prompt = prompt + line + '\\n'\n",
    "            n_tokens += num_new_tokens\n",
    "        else:\n",
    "            # Maximum amount of tokens exceeded, send the accumulated prompt to ChatGPT\n",
    "            print('prompting', prompt)\n",
    "            ans = prompt_chatgpt(prompt)\n",
    "            score = int(re.findall('\\d', ans)[0])\n",
    "            print('got score of', score)\n",
    "            scores.append(score)\n",
    "\n",
    "            prompt = query + line + '\\n'\n",
    "            n_tokens = len(prompt.split(' '))\n",
    "        \n",
    "    if n_tokens > len(query.split(' ')):\n",
    "        ans = prompt_chatgpt(prompt)\n",
    "        score = int(re.findall('\\d', ans)[0])\n",
    "        print('got score of', score)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(scores)\n",
    "    return np.mean(scores)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlephBert Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at onlplab/alephbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "alephbert_tokenizer = AutoTokenizer.from_pretrained('onlplab/alephbert-base')\n",
    "alephbert = AutoModelForSequenceClassification.from_pretrained('onlplab/alephbert-base', num_labels=2)\n",
    "\n",
    "# Freeze the weights of the model\n",
    "for param in list(alephbert.parameters())[:-1]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "agg_scores_df = pd.read_csv('agg_score_bin.csv')\n",
    "agg_scores_df.dropna(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(agg_scores_df, test_size=0.2)\n",
    "\n",
    "# Reset the index of each DataFrame\n",
    "train_set.reset_index(drop=True, inplace=True)\n",
    "test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "agg_train = Dataset(train_set['text'], train_set['score'])\n",
    "agg_test = Dataset(test_set['text'], test_set['score'])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(agg_train, batch_size=16, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(agg_test, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [01:51<00:00,  4.86s/it]\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [01:29<00:00,  3.91s/it]\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5/23 [00:17<00:59,  3.28s/it]"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alephbert.to(device)\n",
    "\n",
    "# Set optimizer and loss function\n",
    "optimizer = torch.optim.Adam(alephbert.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train model\n",
    "alephbert.train()\n",
    "for epoch in range(25):\n",
    "    print('epoch', epoch)\n",
    "    for texts, scores in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        scores = scores.long().to(device)\n",
    "        inputs = alephbert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        outputs = alephbert(**inputs, return_dict=False)[0]\n",
    "\n",
    "        loss = criterion(outputs, scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total accuracy on test set: 0.5869565217391305\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "alephbert.eval()\n",
    "preds_df = pd.DataFrame(columns=['predictions', 'scores'])\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, scores in test_dataloader:\n",
    "        inputs = alephbert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        scores = scores.to(device)\n",
    "\n",
    "        outputs = alephbert(**inputs, return_dict=False)[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += scores.size(0)\n",
    "        correct += (predicted == scores).sum().item()\n",
    "\n",
    "        # outputs = outputs.reshape((16,))\n",
    "\n",
    "        # agg score is between 1 to 7\n",
    "        # outputs = np.round(outputs)\n",
    "        \n",
    "        d = {'predictions': [o.item() for o in predicted], 'scores': [s.item() for s in scores]}\n",
    "        df = pd.DataFrame.from_dict(d)\n",
    "        preds_df = pd.concat([preds_df, df], ignore_index=True, copy=False)\n",
    "\n",
    "print('total accuracy on test set:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>81</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predictions  scores\n",
       "count            92      92\n",
       "unique            2       2\n",
       "top               0       0\n",
       "freq             81      49"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlephBert Regression Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c'] = df['c'].apply(lambda x: int(x>=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  0\n",
       "1  4  5  1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>התחלנו, בוקר טוב - - -\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>אפשר לקרוא את החומר, אני לא הספקתי לקרוא. \\n</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>אז בבקשה, יש לכם את החומרים וגם שלחתי לכם את ז...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>יש לנו עכשיו, את תתני לנו לקרוא?\\n</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>בטח, בטח, בבקשה, תוכלו לקרוא - - -\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>אה, אוסאמה, אני נותן לך לדבר.\\n</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>תודה, תודה ביטן שאתה נותן לי לדבר.\\n</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>מאה אחוז. \\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>אתם מתנהגים עם טריקים ועם שטיקים. \\n</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>תסתכל עליה. המצלמה חושבת - - -\\n</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  score\n",
       "0                             התחלנו, בוקר טוב - - -\\n    1.0\n",
       "1         אפשר לקרוא את החומר, אני לא הספקתי לקרוא. \\n    4.0\n",
       "2    אז בבקשה, יש לכם את החומרים וגם שלחתי לכם את ז...    3.0\n",
       "3                   יש לנו עכשיו, את תתני לנו לקרוא?\\n    5.0\n",
       "4                 בטח, בטח, בבקשה, תוכלו לקרוא - - -\\n    1.0\n",
       "..                                                 ...    ...\n",
       "455                    אה, אוסאמה, אני נותן לך לדבר.\\n    3.0\n",
       "456               תודה, תודה ביטן שאתה נותן לי לדבר.\\n    3.0\n",
       "457                                       מאה אחוז. \\n    1.0\n",
       "458               אתם מתנהגים עם טריקים ועם שטיקים. \\n    5.0\n",
       "459                   תסתכל עליה. המצלמה חושבת - - -\\n    5.0\n",
       "\n",
       "[460 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_scores_df.to_csv('agg_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "116ca426afd871d658ee678036fa2f9ff9ea33b2a9b8c09422f19bc5af964702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
