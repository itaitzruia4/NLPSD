{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import torch\n",
    "\n",
    "from consts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kns_csv_files/kns_committee.csv')\n",
    "df = df[df['KnessetNum'] >= 25]\n",
    "df = df[df['CategoryID'].isin([MONEY_COM_CATEGORY_ID, DEFENSE_COM_CATEGORY_ID, LAW_ORDER_COM_CATEGORY_ID, MESADERET_COM_CATEGORY_ID, KNESSET_COM_CATEGORY_ID])]\n",
    "commitee_ids = df['CommitteeID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_protocol_text(text_path):\n",
    "    # Define the URL to fetch\n",
    "    base_url = 'https://production.oknesset.org/pipelines/data/committees/meeting_protocols_text/'\n",
    "    # Send GET request to the URL\n",
    "    response = requests.get(base_url + text_path)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        # Retrieve the content of the file\n",
    "        return response.text\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to retrieve content. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_session_df = pd.read_csv('kns_csv_files/kns_committeesession.csv')\n",
    "com_session_df = com_session_df[com_session_df['CommitteeID'].isin(commitee_ids)]\n",
    "\n",
    "com_session_df.dropna(subset=['text_parsed_filename'], inplace=True)\n",
    "text_paths = com_session_df['text_parsed_filename'].to_list()\n",
    "texts = [get_meeting_protocol_text(path) for path in text_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knesset_members_df = pd.read_csv('kns_csv_files/kns_person.csv')\n",
    "first_names, last_names = knesset_members_df['FirstName'].to_list(), knesset_members_df['LastName'].to_list()\n",
    "knesset_members = [' '.join([first_name, last_name]) for first_name, last_name in zip(first_names, last_names)]\n",
    "\n",
    "warnings = {mem: [0, 0, 0] for mem in knesset_members}\n",
    "\n",
    "# handle members with a middle name or a nickname\n",
    "new_first_names, new_last_names = [], []\n",
    "\n",
    "for fn, ln in zip(first_names, last_names):\n",
    "    names = re.findall('\\w+', fn)\n",
    "    \n",
    "    for name in names:\n",
    "        warnings[name + ' ' + ln] = warnings[fn + ' ' + ln]\n",
    "        new_first_names.append(name)\n",
    "        new_last_names.append(ln)\n",
    "\n",
    "# update first and last names\n",
    "first_names = new_first_names\n",
    "last_names = new_last_names\n",
    "\n",
    "knesset_members = [' '.join([first_name, last_name]) for first_name, last_name in zip(first_names, last_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_warnings(text, warnings, knesset_members) -> None:\n",
    "    \"\"\"\n",
    "    Return warnings from the meeting protocol text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Meeting protocol text.\n",
    "\n",
    "    warnings: Dict[str, List[int]]\n",
    "        Number of warnings for each Knesset member.\n",
    "\n",
    "    knesset_members: List[str]\n",
    "        List of Knesset members.\n",
    "    \"\"\"\n",
    "\n",
    "    # find all warnings\n",
    "    matches = re.findall(WARNING_REGEX, text, flags=re.MULTILINE)\n",
    "    print(len(matches))\n",
    "    for i, match in enumerate(matches):\n",
    "        print(f'match #{i}:')\n",
    "        print(match)\n",
    "        sentences = match.split('\\n')\n",
    "        first_sentence, last_sentence = sentences[0], sentences[-1]\n",
    "        for kns_member in knesset_members:\n",
    "            if kns_member in first_sentence:\n",
    "                word2idx = {'ראש': 0, 'שני': 1, 'שליש': 2}\n",
    "                for word, idx in word2idx.items():\n",
    "                    if word in last_sentence:\n",
    "                        warnings[kns_member][idx] += 1\n",
    "                        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alephbert_tokenizer = BertTokenizerFast.from_pretrained('onlplab/alephbert-base')\n",
    "alephbert = BertModel.from_pretrained('onlplab/alephbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-7.5732e-01,  5.3082e-02, -6.2342e-01,  ..., -3.4851e-01,\n",
      "           1.5200e-01,  5.9104e-02],\n",
      "         [ 2.2266e-01, -8.5340e-01, -2.5723e-02,  ..., -6.8251e-01,\n",
      "           4.8405e-01, -2.7740e-01],\n",
      "         [ 1.4334e+00, -2.0554e-02,  3.7486e-01,  ...,  1.6602e-01,\n",
      "           1.2668e+00, -1.6225e-01],\n",
      "         ...,\n",
      "         [ 1.2939e+00, -5.1341e-01,  3.2570e-01,  ...,  4.7693e-05,\n",
      "           9.7235e-01, -5.4676e-01],\n",
      "         [ 1.3832e+00, -1.2884e+00, -2.6654e-01,  ...,  1.4298e+00,\n",
      "           3.7618e-01,  5.9848e-01],\n",
      "         [ 7.1438e-01, -6.4273e-01, -5.7363e-01,  ..., -3.5674e-01,\n",
      "           3.1811e-01, -3.2872e-01]]]), pooler_output=tensor([[ 0.0143,  0.1606, -0.1559, -0.1836,  0.4954, -0.2131,  0.6380,  0.5410,\n",
      "         -0.3370, -0.3516,  0.3491, -0.5018, -0.1477, -0.0547,  0.6812, -0.0139,\n",
      "          0.4014,  0.4610, -0.1625, -0.1118, -0.2276,  0.0291, -0.5252,  0.6775,\n",
      "         -0.2995, -0.4915, -0.4297,  0.0410,  0.5296, -0.0249,  0.2592, -0.8312,\n",
      "         -0.7939, -0.0687, -0.1688,  0.5589,  0.3034, -0.7617,  0.6355, -0.0395,\n",
      "         -0.8120, -0.5828, -0.1315, -0.1524, -0.2396, -0.8850,  0.0121,  0.2970,\n",
      "          0.4436, -0.7652,  0.6806,  0.0448,  0.0375,  0.2344, -0.2106,  0.4301,\n",
      "         -0.1038,  0.0087,  0.1036,  0.5738,  0.1858, -0.4486,  0.3570,  0.2896,\n",
      "          0.4512, -0.0931,  0.5531, -0.6931,  0.1277, -0.1995,  0.1864, -0.5856,\n",
      "         -0.0221, -0.1168,  0.3655, -0.4360, -0.2970, -0.7125,  0.2487, -0.8135,\n",
      "         -0.5963, -0.0294,  0.2757, -0.3800, -0.0473, -0.1141, -0.0858,  0.1791,\n",
      "         -0.0662,  0.5214, -0.3266, -0.3441, -0.7578,  0.1153, -0.6068,  0.2321,\n",
      "         -0.0225, -0.0786, -0.0931,  0.1123,  0.4752,  0.6795,  0.1207, -0.1997,\n",
      "          0.3171, -0.5763, -0.4959, -0.0506,  0.6254,  0.5562, -0.7245,  0.5433,\n",
      "         -0.1509, -0.1248, -0.1229, -0.4003, -0.3082,  0.7743,  0.7239,  0.9421,\n",
      "          0.3282,  0.5582, -0.7133,  0.5501,  0.8440,  0.0121, -0.7154, -0.2012,\n",
      "         -0.7034, -0.7013, -0.1718,  0.8867, -0.2797, -0.4424, -0.3054,  0.6614,\n",
      "         -0.0454,  0.1202,  0.2215, -0.1563, -0.0265,  0.4200, -0.2471, -0.4313,\n",
      "          0.9073,  0.0461,  0.6921,  0.0040,  0.5944, -0.4620,  0.2641, -0.5323,\n",
      "          0.2591, -0.9132,  0.4288,  0.4312,  0.5170, -0.0676,  0.0729, -0.1031,\n",
      "          0.4554,  0.5456,  0.6217, -0.2167, -0.0827, -0.2471,  0.6117,  0.2088,\n",
      "         -0.3423, -0.0825,  0.1395, -0.3823,  0.7908,  0.0961,  0.4721, -0.0025,\n",
      "          0.5610, -0.2349,  0.1487,  0.0589, -0.1189, -0.4216, -0.2781, -0.2845,\n",
      "         -0.4608,  0.4537, -0.3809, -0.6708,  0.0845,  0.2544, -0.2729, -0.2451,\n",
      "          0.2087, -0.5883, -0.1752,  0.7282,  0.4212, -0.1811,  0.0743, -0.3383,\n",
      "         -0.7555,  0.1256,  0.2344, -0.1034,  0.3014,  0.1809, -0.6701, -0.2066,\n",
      "         -0.3334, -0.0217,  0.6694,  0.4243,  0.0472,  0.6214, -0.4072,  0.7360,\n",
      "          0.0524, -0.0615, -0.1138,  0.2261,  0.3495,  0.0089,  0.7520,  0.3596,\n",
      "          0.5789, -0.0396, -0.2203, -0.8291,  0.0883,  0.1730,  0.4274,  0.4792,\n",
      "         -0.1980, -0.3286, -0.0255, -0.1120, -0.0756,  0.8015,  0.0733,  0.1811,\n",
      "          0.0595, -0.0839,  0.2529,  0.1009, -0.6107,  0.1622, -0.4041, -0.4713,\n",
      "         -0.4925,  0.2635, -0.2778,  0.5488, -0.8328, -0.6352,  0.1672,  0.4391,\n",
      "          0.4869,  0.2416, -0.2439, -0.0484, -0.6513, -0.1129, -0.2053,  0.0398,\n",
      "          0.0456,  0.6154,  0.3567,  0.0404, -0.3574, -0.0803,  0.4809,  0.9143,\n",
      "         -0.0373,  0.1475,  0.3610,  0.5891,  0.3718, -0.0456, -0.4325, -0.3964,\n",
      "         -0.0165, -0.3918, -0.5602, -0.1118,  0.5703,  0.1688, -0.2588, -0.3846,\n",
      "          0.7684, -0.6064,  0.5079,  0.5399, -0.1233, -0.1223, -0.2676, -0.3800,\n",
      "          0.3357, -0.6777,  0.5660, -0.4206,  0.2296,  0.4506, -0.7334, -0.1285,\n",
      "         -0.1948, -0.8406, -0.7939, -0.1285,  0.0493,  0.6471,  0.1586, -0.3065,\n",
      "          0.2224, -0.0724, -0.2028, -0.1273, -0.3909,  0.0344, -0.2023,  0.6188,\n",
      "         -0.1674,  0.0571, -0.0084, -0.1909, -0.3145, -0.4232,  0.1831, -0.2466,\n",
      "          0.6487, -0.4934, -0.0552, -0.0229,  0.2183,  0.3310, -0.2451, -0.2509,\n",
      "          0.2876, -0.2412,  0.5041, -0.7446,  0.0494,  0.6355,  0.7742, -0.4990,\n",
      "         -0.5103,  0.3299, -0.3246,  0.1954,  0.1497, -0.3299,  0.5417, -0.6707,\n",
      "         -0.3356,  0.3974,  0.1096,  0.1410,  0.6890, -0.6083, -0.1823,  0.7830,\n",
      "         -0.6671,  0.1871,  0.0118,  0.1585, -0.6520,  0.4525,  0.8492, -0.4010,\n",
      "         -0.1114, -0.3057, -0.2018,  0.7761, -0.7422, -0.2311, -0.3584,  0.6534,\n",
      "         -0.3205,  0.3517,  0.8686, -0.0018, -0.0031, -0.1376,  0.1727,  0.3933,\n",
      "          0.1647, -0.1109,  0.2378, -0.4843, -0.4564,  0.2578,  0.1347,  0.2015,\n",
      "          0.1190, -0.5710, -0.0938, -0.0566, -0.0989, -0.4146,  0.8256, -0.2991,\n",
      "          0.7565, -0.5185,  0.1290,  0.2655,  0.0812, -0.4403,  0.1072, -0.1057,\n",
      "          0.0133,  0.1354, -0.3481,  0.2824,  0.6305, -0.4419,  0.8963,  0.4659,\n",
      "          0.2052, -0.2668, -0.4883, -0.4708, -0.7404, -0.1155, -0.1127, -0.2402,\n",
      "         -0.8322,  0.2175, -0.2600, -0.6488, -0.5004,  0.1570, -0.5156, -0.3036,\n",
      "          0.6866,  0.4947, -0.4056, -0.7371, -0.8864,  0.6794, -0.7967,  0.3076,\n",
      "          0.6244, -0.2703,  0.1765,  0.0374, -0.0365,  0.1267,  0.4107,  0.3612,\n",
      "          0.3959,  0.4659,  0.1998, -0.2520,  0.6831,  0.6068, -0.7769, -0.3612,\n",
      "         -0.0313,  0.5531, -0.4841, -0.1947,  0.0608, -0.2038,  0.1292, -0.3812,\n",
      "          0.7937,  0.0538,  0.2496, -0.2571, -0.2675,  0.6002,  0.0236, -0.3560,\n",
      "          0.5472, -0.3065, -0.5131, -0.2643, -0.7783, -0.6951, -0.8519,  0.7534,\n",
      "          0.0457,  0.0083, -0.3227,  0.1474,  0.6351, -0.4797, -0.3496, -0.3397,\n",
      "          0.5585,  0.2001,  0.0187, -0.6199, -0.2368,  0.4017,  0.1563, -0.0352,\n",
      "          0.0230, -0.1822, -0.4607, -0.3359,  0.5641,  0.1923,  0.0063, -0.6048,\n",
      "          0.7227,  0.3142,  0.1480,  0.2124,  0.1119, -0.6401, -0.6513, -0.2657,\n",
      "          0.1846, -0.3440,  0.4129, -0.3877,  0.6225,  0.1497, -0.1192,  0.0086,\n",
      "         -0.6087, -0.5910, -0.1834,  0.7344,  0.3554, -0.7063,  0.9320, -0.5065,\n",
      "          0.3322,  0.1442, -0.4953,  0.0295,  0.4091,  0.7027, -0.3853,  0.2105,\n",
      "          0.0704,  0.2657, -0.1289,  0.2154, -0.0499,  0.3262,  0.0117, -0.2851,\n",
      "          0.8809,  0.7106, -0.5521,  0.6852, -0.2563, -0.3045,  0.4506,  0.1412,\n",
      "          0.2347,  0.1700,  0.3425,  0.2934, -0.0561, -0.7975,  0.6124, -0.4780,\n",
      "          0.3669,  0.2568,  0.3984,  0.0849, -0.1846, -0.2432, -0.8078,  0.2834,\n",
      "          0.0740, -0.6579, -0.1555,  0.0369, -0.1117, -0.3533,  0.3804,  0.2340,\n",
      "         -0.4189, -0.1153,  0.2455,  0.7645,  0.6018, -0.3609,  0.2266, -0.2215,\n",
      "          0.6079,  0.3806, -0.2536,  0.6933, -0.3939, -0.3185, -0.5293, -0.5615,\n",
      "          0.6011, -0.4716,  0.1698, -0.2098, -0.5319,  0.0793, -0.5574, -0.1308,\n",
      "         -0.8088, -0.6261,  0.7153,  0.2717, -0.1734,  0.5860, -0.1306,  0.3919,\n",
      "          0.0746, -0.1336,  0.5287,  0.2549,  0.5041,  0.2935, -0.0169, -0.3065,\n",
      "          0.8437,  0.4640, -0.5587,  0.7133, -0.3367, -0.2747,  0.3541,  0.4478,\n",
      "          0.0056, -0.4677,  0.3521, -0.2348, -0.5453, -0.6231, -0.4377, -0.5826,\n",
      "          0.1676,  0.3655,  0.6692,  0.5037,  0.1043, -0.4274,  0.2373,  0.0975,\n",
      "         -0.5347, -0.4217,  0.1786,  0.3161,  0.2479, -0.0823, -0.4360,  0.6185,\n",
      "          0.5076,  0.4730, -0.5426,  0.6189,  0.0897,  0.4589, -0.0877,  0.1194,\n",
      "         -0.0378, -0.0409,  0.5291, -0.5385,  0.1876,  0.4134,  0.4405,  0.7278,\n",
      "          0.1354,  0.4605, -0.1667, -0.2795,  0.2330, -0.8678,  0.5819, -0.7193,\n",
      "          0.5720,  0.5421, -0.4908,  0.3168, -0.7943, -0.2355,  0.3296,  0.1615,\n",
      "          0.3529,  0.2895, -0.1826, -0.1912, -0.2308, -0.2193,  0.4060,  0.1371,\n",
      "          0.5131,  0.7141,  0.2692,  0.0091, -0.4841, -0.2459, -0.2985,  0.3744,\n",
      "          0.5230, -0.1281,  0.9004,  0.7088,  0.8959, -0.3090, -0.2736, -0.0049,\n",
      "          0.4803, -0.1377, -0.2794,  0.8722,  0.1645, -0.0851,  0.3231,  0.3524,\n",
      "         -0.5635,  0.6558, -0.8987, -0.3458, -0.2556, -0.5525, -0.3282,  0.3552,\n",
      "          0.1348,  0.8773, -0.3503,  0.5504,  0.2974, -0.4204,  0.1053, -0.7612,\n",
      "          0.4870, -0.2958, -0.7604,  0.5326, -0.2528,  0.3573, -0.0914,  0.5094,\n",
      "          0.6176,  0.4172,  0.0286,  0.4374,  0.0096,  0.7478,  0.0144, -0.1048,\n",
      "          0.4941,  0.1164,  0.3273, -0.1713, -0.1862, -0.1774,  0.5446, -0.4551,\n",
      "         -0.2960,  0.4720, -0.5539, -0.0674,  0.3013, -0.0665, -0.0685, -0.1003,\n",
      "          0.1540,  0.5157, -0.3741,  0.4473, -0.5266, -0.2343, -0.4369,  0.6905]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "logists shape: torch.Size([1, 11, 768])\n",
      "logits: tensor([[[-7.5732e-01,  5.3082e-02, -6.2342e-01,  ..., -3.4851e-01,\n",
      "           1.5200e-01,  5.9104e-02],\n",
      "         [ 2.2266e-01, -8.5340e-01, -2.5723e-02,  ..., -6.8251e-01,\n",
      "           4.8405e-01, -2.7740e-01],\n",
      "         [ 1.4334e+00, -2.0554e-02,  3.7486e-01,  ...,  1.6602e-01,\n",
      "           1.2668e+00, -1.6225e-01],\n",
      "         ...,\n",
      "         [ 1.2939e+00, -5.1341e-01,  3.2570e-01,  ...,  4.7693e-05,\n",
      "           9.7235e-01, -5.4676e-01],\n",
      "         [ 1.3832e+00, -1.2884e+00, -2.6654e-01,  ...,  1.4298e+00,\n",
      "           3.7618e-01,  5.9848e-01],\n",
      "         [ 7.1438e-01, -6.4273e-01, -5.7363e-01,  ..., -3.5674e-01,\n",
      "           3.1811e-01, -3.2872e-01]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 768 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_376\\671861103.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logits:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 768 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# if not finetuning - disable dropout\n",
    "alephbert.eval()\n",
    "text = 'מי אתה בכלל שתרים את הקול שלך עליי'\n",
    "encoding = alephbert_tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    output = alephbert(**encoding)\n",
    "    print('output:', output)\n",
    "    logits = output[0]\n",
    "    print('logists shape:', logits.shape)\n",
    "    print('logits:', logits)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    print(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_init__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'attentions',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'cross_attentions',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'hidden_states',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'last_hidden_state',\n",
       " 'move_to_end',\n",
       " 'past_key_values',\n",
       " 'pooler_output',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'to_tuple',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.5732e-01,  5.3082e-02, -6.2342e-01,  ..., -3.4851e-01,\n",
       "           1.5200e-01,  5.9104e-02],\n",
       "         [ 2.2266e-01, -8.5340e-01, -2.5723e-02,  ..., -6.8251e-01,\n",
       "           4.8405e-01, -2.7740e-01],\n",
       "         [ 1.4334e+00, -2.0554e-02,  3.7486e-01,  ...,  1.6602e-01,\n",
       "           1.2668e+00, -1.6225e-01],\n",
       "         ...,\n",
       "         [ 1.2939e+00, -5.1341e-01,  3.2570e-01,  ...,  4.7693e-05,\n",
       "           9.7235e-01, -5.4676e-01],\n",
       "         [ 1.3832e+00, -1.2884e+00, -2.6654e-01,  ...,  1.4298e+00,\n",
       "           3.7618e-01,  5.9848e-01],\n",
       "         [ 7.1438e-01, -6.4273e-01, -5.7363e-01,  ..., -3.5674e-01,\n",
       "           3.1811e-01, -3.2872e-01]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "116ca426afd871d658ee678036fa2f9ff9ea33b2a9b8c09422f19bc5af964702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
