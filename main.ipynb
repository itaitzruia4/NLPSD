{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import openai\n",
    "\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from consts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kns_csv_files/kns_committee.csv')\n",
    "df = df[df['KnessetNum'] >= 25]\n",
    "df = df[df['CategoryID'].isin([MONEY_COM_CATEGORY_ID, DEFENSE_COM_CATEGORY_ID, LAW_ORDER_COM_CATEGORY_ID, MESADERET_COM_CATEGORY_ID, KNESSET_COM_CATEGORY_ID])]\n",
    "commitee_ids = df['CommitteeID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_protocol_text(text_path):\n",
    "    # Define the URL to fetch\n",
    "    base_url = 'https://production.oknesset.org/pipelines/data/committees/meeting_protocols_text/'\n",
    "    # Send GET request to the URL\n",
    "    response = requests.get(base_url + text_path)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "        # Retrieve the content of the file\n",
    "        return response.text\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to retrieve content. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='production.oknesset.org', port=443): Max retries exceeded with url: /pipelines/data/committees/meeting_protocols_text/files/2/1/2197382.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000016E83378220>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x0000016E83378220>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='production.oknesset.org', port=443): Max retries exceeded with url: /pipelines/data/committees/meeting_protocols_text/files/2/1/2197382.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000016E83378220>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24988\\2522381786.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcom_session_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_parsed_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom_session_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_parsed_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_meeting_protocol_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0magg_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrate_aggressiveness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24988\\2522381786.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcom_session_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_parsed_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom_session_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_parsed_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_meeting_protocol_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0magg_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrate_aggressiveness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24988\\3898776884.py\u001b[0m in \u001b[0;36mget_meeting_protocol_text\u001b[1;34m(text_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbase_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://production.oknesset.org/pipelines/data/committees/meeting_protocols_text/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Send GET request to the URL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Check if the request was successful (status code 200)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\merav\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='production.oknesset.org', port=443): Max retries exceeded with url: /pipelines/data/committees/meeting_protocols_text/files/2/1/2197382.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000016E83378220>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))"
     ]
    }
   ],
   "source": [
    "com_session_df = pd.read_csv('kns_csv_files/kns_committeesession.csv')\n",
    "com_session_df = com_session_df[com_session_df['CommitteeID'].isin(commitee_ids)]\n",
    "\n",
    "com_session_df.dropna(subset=['text_parsed_filename'], inplace=True)\n",
    "text_paths = com_session_df['text_parsed_filename'].to_list()\n",
    "texts = [get_meeting_protocol_text(path) for path in text_paths]\n",
    "agg_scores = [rate_aggressiveness(text) for text in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knesset_members_df = pd.read_csv('kns_csv_files/kns_person.csv')\n",
    "first_names, last_names = knesset_members_df['FirstName'].to_list(), knesset_members_df['LastName'].to_list()\n",
    "knesset_members = [' '.join([first_name, last_name]) for first_name, last_name in zip(first_names, last_names)]\n",
    "\n",
    "warnings = {mem: [0, 0, 0] for mem in knesset_members}\n",
    "\n",
    "# handle members with a middle name or a nickname\n",
    "new_first_names, new_last_names = [], []\n",
    "\n",
    "for fn, ln in zip(first_names, last_names):\n",
    "    names = re.findall('\\w+', fn)\n",
    "    \n",
    "    for name in names:\n",
    "        warnings[name + ' ' + ln] = warnings[fn + ' ' + ln]\n",
    "        new_first_names.append(name)\n",
    "        new_last_names.append(ln)\n",
    "\n",
    "# update first and last names\n",
    "first_names = new_first_names\n",
    "last_names = new_last_names\n",
    "\n",
    "knesset_members = [' '.join([first_name, last_name]) for first_name, last_name in zip(first_names, last_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_warnings(text, warnings, knesset_members) -> None:\n",
    "    \"\"\"\n",
    "    Return warnings from the meeting protocol text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Meeting protocol text.\n",
    "\n",
    "    warnings: Dict[str, List[int]]\n",
    "        Number of warnings for each Knesset member.\n",
    "\n",
    "    knesset_members: List[str]\n",
    "        List of Knesset members.\n",
    "    \"\"\"\n",
    "\n",
    "    # find all warnings\n",
    "    matches = re.findall(WARNING_REGEX, text, flags=re.MULTILINE)\n",
    "    print(len(matches))\n",
    "    for i, match in enumerate(matches):\n",
    "        print(f'match #{i}:')\n",
    "        print(match)\n",
    "        sentences = match.split('\\n')\n",
    "        first_sentence, last_sentence = sentences[0], sentences[-1]\n",
    "        for kns_member in knesset_members:\n",
    "            if kns_member in first_sentence:\n",
    "                word2idx = {'ראש': 0, 'שני': 1, 'שליש': 2}\n",
    "                for word, idx in word2idx.items():\n",
    "                    if word in last_sentence:\n",
    "                        warnings[kns_member][idx] += 1\n",
    "                        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at onlplab/alephbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "alephbert_tokenizer = AutoTokenizer.from_pretrained('onlplab/alephbert-base')\n",
    "alephbert = AutoModelForSequenceClassification.from_pretrained('onlplab/alephbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: SequenceClassifierOutput(loss=None, logits=tensor([[-0.2032, -0.2492]]), hidden_states=None, attentions=None)\n",
      "logists shape: torch.Size([1, 2])\n",
      "logits: tensor([[-0.2032, -0.2492]])\n"
     ]
    }
   ],
   "source": [
    "# if not finetuning - disable dropout\n",
    "alephbert.eval()\n",
    "text = 'מי אתה בכלל שתרים את הקול שלך עליי?'\n",
    "\n",
    "inputs = alephbert_tokenizer(text, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = alephbert(input_ids, attention_mask=attention_mask)\n",
    "    print('output:', outputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    print('logists shape:', logits.shape)\n",
    "    print('logits:', logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chatgpt(prompt: str) -> str:\n",
    "    openai.my_api_key = open('../chatgpt-key.txt', 'r').read().strip('\\n')\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are an intelligent assistant.'},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print('answer from chatgpt:\\n', response)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_protocol_sentences(text: str) -> str:\n",
    "    ind = re.search(\"<< יור >>\", text)\n",
    "    txt2 = text[ind.span()[0]:]\n",
    "    txt2 = re.sub(\"<<.*\",\"\", txt2)\n",
    "    txt2 = re.sub(\">>.*\",\"\", txt2)\n",
    "    txt2 = re.sub(\"\\n\\s+\",\"\\n\", txt2)\n",
    "    txt2 = re.sub(\" +\",\" \", txt2)\n",
    "    return txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('protocols/2159679.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "filtered_text = filter_protocol_sentences(text)\n",
    "with open('filtered_protocols/2159679.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_aggressiveness(text):\n",
    "    filtered_text = filter_protocol_sentences(text)\n",
    "    lines = filtered_text.split('\\n')\n",
    "\n",
    "    # Filter non-conversation related lines\n",
    "    lines = [line for line in lines if line.strip() != '' and '>' not in line and '<' not in line]\n",
    "    print(lines)\n",
    "\n",
    "    # Prompt Chat-GPT to rate the aggressiveness of the text\n",
    "    scores = []\n",
    "    query = 'דרג את מידת האגרסיביות של השיחה (תשובה מספרית בלבד! מ-1 עד 5 כש-5 זה אגרסיבי מאוד)\\n'\n",
    "\n",
    "    prompt = query\n",
    "    n_tokens = len(prompt.split(' '))\n",
    "\n",
    "    for line in lines:\n",
    "        print('prompt:', prompt)\n",
    "        print('n_tokens:', n_tokens)\n",
    "        print('curr line:', line)\n",
    "\n",
    "        num_new_tokens = len(line.split(' '))\n",
    "        print('num new tokens:', num_new_tokens)\n",
    "        if n_tokens + num_new_tokens < CHATGPT_MAX_TOKENS:\n",
    "            # Maximum amount of tokens not yet exceeded, can add another sentence\n",
    "            prompt = prompt + line + '\\n'\n",
    "            n_tokens += num_new_tokens\n",
    "        else:\n",
    "            # Maximum amount of tokens exceeded, send the accumulated prompt to ChatGPT\n",
    "            print('prompting', prompt)\n",
    "            ans = prompt_chatgpt(prompt)\n",
    "            score = int(re.findall('\\d', ans)[0])\n",
    "            print('got score of', score)\n",
    "            scores.append(score)\n",
    "\n",
    "            prompt = query + line + '\\n'\n",
    "            n_tokens = len(prompt.split(' '))\n",
    "        \n",
    "    if n_tokens > len(query.split(' ')):\n",
    "        ans = prompt_chatgpt(prompt)\n",
    "        score = int(re.findall('\\d', ans)[0])\n",
    "        print('got score of', score)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(scores)\n",
    "    return np.mean(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "\n",
    "הכנסת העשרים-וארבע\n",
    "\n",
    "הכנסת\n",
    "\n",
    "\n",
    "\n",
    "2\n",
    "ועדת הכנסת\n",
    "25/04/2022\n",
    "\n",
    "\n",
    "03/05/2022\n",
    "10:35\n",
    "מושב שני\n",
    "\n",
    "\n",
    "\n",
    "פרוטוקול מס' 89\n",
    "מישיבת ועדת הכנסת\n",
    "יום שני, כ\"ד בניסן התשפ\"ב (25 באפריל 2022), שעה 10:00\n",
    "\n",
    "\n",
    "\n",
    "סדר היום:\n",
    " << נושא >> פניית ראש הממשלה ויו\"ר ימינה, חה\"כ נפתלי בנט, בבקשה להכריז על חבר הכנסת עמיחי שיקלי כפורש מסיעת ימינה. << נושא >>   \n",
    "\n",
    "\n",
    "נכחו:\n",
    "חברי הוועדה: \n",
    "איתן גינזבורג – מ\"מ היו\"ר\n",
    "רם שפע – מ\"מ היו\"ר\n",
    "בועז טופורובסקי\n",
    "אחמד טיבי\n",
    "יבגני סובה\n",
    "יצחק פינדרוס\n",
    "\n",
    "\n",
    "חברי הכנסת:\n",
    "יולי אדלשטיין\n",
    "אמיר אוחנה\n",
    "ינון אזולאי\n",
    "דוד אמסלם\n",
    "אופיר אקוניס\n",
    "משה ארבל\n",
    "בני בגין\n",
    "ולדימיר בליאק\n",
    "איתמר בן גביר\n",
    "יואב בן צור\n",
    "גילה גמליאל\n",
    "צחי הנגבי\n",
    "מיכל וולדיגר\n",
    "משה טור פז\n",
    "אלי כהן\n",
    "אופיר כץ\n",
    "אורלי לוי אבקסיס\n",
    "יריב לוין\n",
    "אבי מעוז\n",
    "אורי מקלב\n",
    "יעקב מרגי\n",
    "אופיר סופר\n",
    "עידית סילמן\n",
    "אורית סטרוק\n",
    "שירלי פינטו\n",
    "יואב קיש\n",
    "שלמה קרעי\n",
    "מירי רגב\n",
    "מיכל רוזין\n",
    "קטי שטרית\n",
    "עמיחי שיקלי\n",
    "נירה שפק\n",
    "\n",
    "\n",
    "מוזמנים: \n",
    "שר הדתות מתן כהנא\n",
    "מזכיר הכנסת דן מרזוק\n",
    "עו\"ד גיא בוסי \t\t– מייצג את חבר הכנסת עמיחי שיקלי\n",
    "עו\"ד עדי סדינסקי-לוי \t– יועץ משפטי לסיעת ימינה \n",
    "עו\"ד עמיחי ויינברג \t– יועץ משפטי לסיעת ימינה\n",
    "\n",
    "\n",
    "ייעוץ משפטי: \n",
    "ארבל אסטרחן\n",
    "\n",
    "מנהלת הוועדה:\n",
    "נועה בירן-דדון\n",
    "\n",
    "רישום פרלמנטרי:\n",
    "שלומית יוסף;\n",
    "הילה לוי;\n",
    "שרון רפאלי;\n",
    "חנה כהן;\n",
    "יפה קרינצה;\n",
    "יפעת קדם;\n",
    "מאיר פרץ;\n",
    "אור שושני;\n",
    "טלי רם;\n",
    "הילה מליחי;\n",
    "ירון קוונשטוק\n",
    "\n",
    "\n",
    "\n",
    " << נושא >> פניית ראש הממשלה ויו\"ר ימינה, חה\"כ נפתלי בנט, בבקשה להכריז על חבר הכנסת עמיחי שיקלי כפורש מסיעת ימינה. << נושא >>   \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "בוקר טוב לכולם. אני מבקש לאפשר לחברי הכנסת מקום לשבת מסביב לשולחן. \n",
    "\n",
    " << דובר >> דוד אמסלם (הליכוד): << דובר >>   \n",
    "\n",
    "הייתם צריכים לעשות במקום יותר גדול. אם הייתה לכם כוונה טובה ולא לשואו, אז בואו תעשו את זה. לא הבנתי, אתה קובע. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "נכון. אז תן לי עכשיו לנהל את הדיון. \n",
    "\n",
    " << דובר >> דוד אמסלם (הליכוד): << דובר >>   \n",
    "\n",
    "גם היום אתם גונבים, כשאתם 60, וכבר התפרקתם. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "עוד לא התחלנו, דודי. תן לי רגע. \n",
    "\n",
    " << דובר >> דוד אמסלם (הליכוד): << דובר >>   \n",
    "\n",
    "עוד לא התחלנו ותראה מה אתם עושים. מה יקרה כשתתחילו? \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "אני סומך עליך. בבקשה, אני רואה פה חברי כנסת שעומדים, אז תאפשרו להם מקום, ובטח לחברי הוועדה שצריכים להיות נוכחים לאורך כל הדיון. \n",
    "\n",
    " << דובר >> דוד אמסלם (הליכוד): << דובר >>   \n",
    "\n",
    "אתם הרי מתביישים במה שאתם עושים. הכנסתם אזרחים עוד לפני שהגענו. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "יש פה גם הרבה מאוד יועצים. אני מציע שיועצים – יש פה לשכות שלמות. יועץ אחד לכל חבר כנסת נראה לי מספיק, ואם יהיה צורך גם נוציא יועצים. אז תאפשרו למי שבאמת נדרש להיות פה בדיון להיות בדיון כדי שנוכל לנהל אותו. \n",
    "\n",
    " << דובר >> עמיחי שיקלי (ימינה): << דובר >>   \n",
    "\n",
    "חבר הכנסת גינזבורג, אני  מבקש שיתאפשר למועמדים של הרשימה להיכנס. כי הוציאו אנשים לפני תחילת הדיון, וזה לא מקובל. הם צריכים להיות פה. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "בוקר טוב לכולם. אני מתכבד לפתוח את ישיבת ועדת הכנסת. ראשית אני רוצה להביע את תנחומיי ולהשתתף בצערו של יושב-ראש ועדת הכנסת, חבר הכנסת ניר אורבך, שאמו יעל נפטרה השבוע, וגם חמותו זלדה שנפטרה גם היא השבוע. אני שולח מכאן חיבוק חזק וחיזוק למשפחת אורבך כולה שעוברת שבוע כואב במיוחד. יהי זכרן ברוך. \n",
    "\n",
    "ניר אורבך ביקש ממני למלא את מקומו בניהול הדיון היום, ולכן אני אנהל את הדיון. על סדר היום פניית יושב-ראש ימינה, ראש הממשלה נפתלי בנט, להכריז על חבר הכנסת עמיחי שיקלי כעל פורש מסיעת ימינה לפי סעיף 6א לחוק יסוד: הכנסת. \n",
    "\n",
    "חברים, אנחנו לא נמצאים בדיון רגיל. זה דיון לא רגיל שלא קורה הרבה בכנסת. זה דיון אישי ויש לו אופי שונה משאר הדיונים בוועדה. \n",
    "\n",
    " << קריאה >> קריאה: << קריאה >>   \n",
    "\n",
    "אופי נכלולי. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "יש עלינו, חברי הוועדה, אחריות גדולה להיכנס ולהקשיב לדברים. \n",
    "\n",
    " << דובר >> אמיר אוחנה (הליכוד): << דובר >>   \n",
    "\n",
    "סליחה, יש פה עיתונאים בחוץ. יש פה עורכת הדין כנרת בראשי. אני מבקש להכניס. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "אני מבקש לא להפריע לי כשאני מדבר בדברי הפתיחה שלי, וזה נראה לי הדבר הכי מינימאלי שאפשר לבקש. \n",
    "\n",
    " << דובר >> אמיר אוחנה (הליכוד): << דובר >>   \n",
    "\n",
    "לא, הדבר הכי מינימלי שהדיון הזה יהיה פומבי, פתוח, כפי שצריך להיות. \n",
    "\n",
    " << יור >> היו\"ר איתן גינזבורג: << יור >>   \n",
    "\n",
    "עוד לא התחיל הדיון, וכבר מפריעים ליושב-ראש לדבר. \n",
    "\n",
    " << דובר >> דוד אמסלם (הליכוד): << דובר >>   \n",
    "\n",
    "קודם כל תתנהל בכלל בפתיחה כמו בן-אדם. טוב שלא השארת אותנו בחוץ ואמרת שלא נותנים לך לדבר.\n",
    "'''\n",
    "\n",
    "rate_aggressiveness(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlephBert Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizerFast, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at onlplab/alephbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "alephbert_tokenizer = BertTokenizerFast.from_pretrained('onlplab/alephbert-base')\n",
    "alephbert = BertModel.from_pretrained('onlplab/alephbert-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'adjust_logits_during_generation',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compute_transition_beam_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'embeddings',\n",
       " 'encoder',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_loaded_in_8bit',\n",
       " 'is_parallelizable',\n",
       " 'load_state_dict',\n",
       " 'load_tf_weights',\n",
       " 'main_input_name',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'pooler',\n",
       " 'post_init',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(alephbert) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>התחלנו, בוקר טוב - - -\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>אפשר לקרוא את החומר, אני לא הספקתי לקרוא. \\n</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>אז בבקשה, יש לכם את החומרים וגם שלחתי לכם את ז...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>יש לנו עכשיו, את תתני לנו לקרוא?\\n</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>בטח, בטח, בבקשה, תוכלו לקרוא - - -\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>אה, אוסאמה, אני נותן לך לדבר.\\n</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>תודה, תודה ביטן שאתה נותן לי לדבר.\\n</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>מאה אחוז. \\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>אתם מתנהגים עם טריקים ועם שטיקים. \\n</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>תסתכל עליה. המצלמה חושבת - - -\\n</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  score\n",
       "0                             התחלנו, בוקר טוב - - -\\n    1.0\n",
       "1         אפשר לקרוא את החומר, אני לא הספקתי לקרוא. \\n    4.0\n",
       "2    אז בבקשה, יש לכם את החומרים וגם שלחתי לכם את ז...    3.0\n",
       "3                   יש לנו עכשיו, את תתני לנו לקרוא?\\n    5.0\n",
       "4                 בטח, בטח, בבקשה, תוכלו לקרוא - - -\\n    1.0\n",
       "..                                                 ...    ...\n",
       "513                    אה, אוסאמה, אני נותן לך לדבר.\\n    3.0\n",
       "514               תודה, תודה ביטן שאתה נותן לי לדבר.\\n    3.0\n",
       "515                                       מאה אחוז. \\n    1.0\n",
       "516               אתם מתנהגים עם טריקים ועם שטיקים. \\n    5.0\n",
       "517                   תסתכל עליה. המצלמה חושבת - - -\\n    5.0\n",
       "\n",
       "[460 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "agg_scores_df = pd.read_csv('agg_score.csv')\n",
    "agg_scores_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(agg_scores_df, test_size=0.2)\n",
    "agg_train = Dataset(train_set['text'], train_set['score'])\n",
    "agg_test = Dataset(test_set['text'], test_set['score'])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(agg_train, batch_size=16, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(agg_test, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning\n",
    "optimizer = AdamW(alephbert_model.parameters(), lr=1e-4)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for epoch in range(5):\n",
    "    for texts, scores in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = alephbert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "        labels = torch.Tensor(scores).unsqueeze(0)\n",
    "        outputs = alephbert_model(**inputs, labels=labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from ChatGPT\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Replace final layer with new classifier layer\n",
    "num_labels = 2 # replace with the number of labels in your classification task\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, num_labels)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prepare data\n",
    "inputs = tokenizer(\"your input text\", padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "labels = torch.tensor([1]).unsqueeze(0).to(device) # replace with your label\n",
    "\n",
    "# Set optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train model\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**inputs, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "116ca426afd871d658ee678036fa2f9ff9ea33b2a9b8c09422f19bc5af964702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
